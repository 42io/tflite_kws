{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2ecnn13.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAbOZ28BZqpE",
        "outputId": "d4ed8d4f-c92f-4a9b-fb91-0e0b15d7765b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov  3 11:18:22 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M09OlPRpDRSh"
      },
      "source": [
        "KERAS_MODELS_ABSOLUTE_PATH = '/content/gdrive/My Drive/2ecnn13'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKHNt4dNhRMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f50401a8-c11e-4b01-d674-0526c58fe1be"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UutF8PBu-oO",
        "outputId": "5711dc7a-b341-4447-b739-f10ed8cc4818"
      },
      "source": [
        "!pip install -qq tensorflow-datasets -U\n",
        "!tfds --version"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.0 MB 4.3 MB/s \n",
            "\u001b[?25hTensorFlow Datasets: 4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T3UOLCpGUmg",
        "outputId": "1a0fc458-13df-47c5-99c4-980bd4901342"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "print(tf.__version__)\n",
        "plt.rc('figure', figsize=(13, 4))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fubso462-iVr"
      },
      "source": [
        "if not tf.io.gfile.exists(KERAS_MODELS_ABSOLUTE_PATH):\n",
        "  print('You should create', KERAS_MODELS_ABSOLUTE_PATH, 'directory manually')\n",
        "  assert False"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQC5dJmvnlm0",
        "outputId": "26b4c97f-5872-414e-b226-0008b682c3be"
      },
      "source": [
        "train_dataset, test_dataset, valid_dataset = tfds.load(\n",
        "    name='my_dataset', split=['train', 'test', 'valid'],\n",
        "    data_dir='gs://tfds-musan-1.appspot.com',\n",
        "    as_supervised=True)\n",
        "train_dataset.cardinality().numpy()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1825800"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AODNDf4J-fVh"
      },
      "source": [
        "train_dataset = train_dataset.map(lambda x, y: (x[1:-1], y)).cache()\n",
        "test_dataset  = test_dataset.map(lambda x, y:  (x[1:-1], y)).cache()\n",
        "valid_dataset = valid_dataset.map(lambda x, y: (x[1:-1], y)).cache()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcj5MHTAKYwv"
      },
      "source": [
        "def spectrogram_masking(spectrogram, dim=1, masks_number=2, mask_max_size=5):\n",
        "  \"\"\"Spectrogram masking on frequency or time dimension.\n",
        "  Args:\n",
        "    spectrogram: Input spectrum [batch, time, frequency]\n",
        "    dim: dimension on which masking will be applied: 1 - time; 2 - frequency\n",
        "    masks_number: number of masks\n",
        "    mask_max_size: mask max size\n",
        "  Returns:\n",
        "    masked spectrogram\n",
        "  \"\"\"\n",
        "  if dim not in (1, 2):\n",
        "    raise ValueError('Wrong dim value: %d' % dim)\n",
        "  input_shape = spectrogram.shape\n",
        "  time_size, frequency_size = input_shape[1:3]\n",
        "  dim_size = input_shape[dim]  # size of dimension on which mask is applied\n",
        "  stripe_shape = [1, time_size, frequency_size]\n",
        "  for _ in range(masks_number):\n",
        "    mask_end = tf.random.uniform([], 0, mask_max_size, tf.int32)\n",
        "    mask_start = tf.random.uniform([], 0, dim_size - mask_end, tf.int32)\n",
        "\n",
        "    # initialize stripes with stripe_shape\n",
        "    stripe_ones_left = list(stripe_shape)\n",
        "    stripe_zeros_center = list(stripe_shape)\n",
        "    stripe_ones_right = list(stripe_shape)\n",
        "\n",
        "    # update stripes dim\n",
        "    stripe_ones_left[dim] = dim_size - mask_start - mask_end\n",
        "    stripe_zeros_center[dim] = mask_end\n",
        "    stripe_ones_right[dim] = mask_start\n",
        "\n",
        "    # generate mask\n",
        "    mask = tf.concat((\n",
        "        tf.ones(stripe_ones_left, spectrogram.dtype),\n",
        "        tf.zeros(stripe_zeros_center, spectrogram.dtype),\n",
        "        tf.ones(stripe_ones_right, spectrogram.dtype),\n",
        "    ), dim)\n",
        "    spectrogram = spectrogram * mask\n",
        "  return spectrogram"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WXRm7NyAtks"
      },
      "source": [
        "def streaming_input_output(streaming, t, inputs, otputs, x):\n",
        "  if streaming:\n",
        "    otputs.append(x)\n",
        "    x = keras.Input(shape=[t] + x.shape[2:])\n",
        "    inputs.append(x)\n",
        "  return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP5AfeDYPYK4"
      },
      "source": [
        "def build_model(in_shape, activation, pooling, out_shape, *in_steps):\n",
        "\n",
        "  # resetting the layer name generation counter\n",
        "  keras.backend.clear_session()\n",
        "\n",
        "  inputs, outputs = [], []\n",
        "  streaming = in_shape[0] == 1\n",
        "\n",
        "  x = x_in = keras.Input(shape=in_shape)\n",
        "\n",
        "  for i in in_steps:\n",
        "    x = keras.layers.Conv1D(i, 1, use_bias=False)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Activation(activation)(x)\n",
        "    x = keras.layers.SpatialDropout1D(i / 1280.0)(x)\n",
        "\n",
        "  for i in range(4):\n",
        "    x = streaming_input_output(streaming, 1 + 2**i, inputs, outputs, x)\n",
        "    x = keras.layers.Conv1D(x.shape[-1], 2,\n",
        "                            dilation_rate=2**i, use_bias=False)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Activation(activation)(x)\n",
        "    x = keras.layers.SpatialDropout1D(0.1)(x)\n",
        "\n",
        "  x = streaming_input_output(streaming, 32, inputs, outputs, x)\n",
        "  x = pooling(x.shape[1])(x)\n",
        "  x = keras.layers.Flatten()(x)\n",
        "\n",
        "  for i in x.shape[-1] * np.array([2, 1]):\n",
        "    x = keras.layers.Dense(i, use_bias=False)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Activation(activation)(x)\n",
        "    x = keras.layers.Dropout(i / 1280.0)(x)\n",
        "\n",
        "  x = keras.layers.Dense(out_shape)(x)\n",
        "  return keras.Model([x_in] + inputs, [x] + outputs, name='second_ensemble')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E84wnQt1s_VY"
      },
      "source": [
        "def build_ensemble(builders=None, models=None, activation=None, streaming=False):\n",
        "  in_shape = (1 if streaming else 47, 13)\n",
        "  if models:\n",
        "    x_in = keras.Input(shape=in_shape)\n",
        "    x = [keras.Model(m.inputs, m.outputs) for m in models]\n",
        "    if streaming:\n",
        "      inputs = [[keras.Input(e.shape[1:]) for e in m.inputs[1:]] for m in x]\n",
        "      x = [e([x_in] + i) for e, i in zip(x, inputs)]\n",
        "      inputs = [i for e in inputs for i in e]\n",
        "      outputs = [i for e in x for i in e[1:]]\n",
        "      x = [e[0] for e in x]\n",
        "    else:\n",
        "      inputs, outputs = [], []\n",
        "      x = [e(x_in) for e in x]\n",
        "    if activation:\n",
        "      x = [keras.layers.Activation(activation)(e) for e in x]\n",
        "      x = keras.layers.Average()(x)\n",
        "    else:\n",
        "      b, c = x\n",
        "      b = tf.squeeze(b, -1)\n",
        "      b = tf.greater(b, 2) # threshold\n",
        "      u = tf.greater(c[:,10], c[:,11])\n",
        "      u = tf.where(u, 10, 11)\n",
        "      x = tf.where(b, tf.argmax(c, -1, u.dtype), u)\n",
        "      x = tf.one_hot(x, 12)\n",
        "    return keras.Model([x_in] + inputs, [x] + outputs)\n",
        "  else:\n",
        "    return tuple(b(in_shape, *a) for b, *a in builders)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6Nk8XnPozIq"
      },
      "source": [
        "models_builders_bin = (\n",
        "  (build_model, 'leaky_relu', keras.layers.MaxPool1D, 1,     128),\n",
        "  (build_model, 'relu',       keras.layers.AvgPool1D, 1,     128),\n",
        "  (build_model, 'relu6',      keras.layers.MaxPool1D, 1, 64, 128),\n",
        "  (build_model, 'elu',        keras.layers.AvgPool1D, 1, 64, 128),\n",
        ")\n",
        "models_bin = build_ensemble(builders=models_builders_bin)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5m9wOJwCxxA"
      },
      "source": [
        "def train_model(model, loss, train_dataset, valid_dataset):\n",
        "\n",
        "  model.compile(\n",
        "    loss=loss(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "  early_stopping = keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        verbose=1,\n",
        "        patience=100,\n",
        "        restore_best_weights=True)\n",
        "\n",
        "  train_batch = train_dataset.shuffle(train_dataset.cardinality())\n",
        "  train_batch = train_batch.batch(128)\n",
        "  train_batch = train_batch.map(lambda x, y: (spectrogram_masking(x, 1, 3, 5), y))\n",
        "  train_batch = train_batch.map(lambda x, y: (spectrogram_masking(x, 2, 2, 2), y))\n",
        "  train_batch = train_batch.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  valid_batch = valid_dataset.batch(128)\n",
        "  valid_batch = valid_batch.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  # plt.imshow(list(train_batch.take(1))[0][0][0].numpy().T)\n",
        "  # plt.show()\n",
        "\n",
        "  history = model.fit(train_batch,\n",
        "                      validation_data=valid_batch,\n",
        "                      callbacks=[early_stopping],\n",
        "                      verbose=2,\n",
        "                      epochs=1000) # play with google colab time limit\n",
        "\n",
        "  model.set_weights(early_stopping.best_weights)\n",
        "  return history"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDdJ8Q2Tx49J"
      },
      "source": [
        "def train_ensemble(ensemble_models, loss, train_dataset, valid_dataset):\n",
        "\n",
        "  for model in ensemble_models:\n",
        "    md5 = str(model.get_config())\n",
        "    md5 = !echo \"$md5\" | md5sum\n",
        "    md5 = md5[0].split()[0]\n",
        "    weights_file = \"%s/%s.h5\" % (KERAS_MODELS_ABSOLUTE_PATH, md5)\n",
        "\n",
        "    if tf.io.gfile.exists(weights_file):\n",
        "      print('Restoring model weights from', md5)\n",
        "      model.load_weights(weights_file)\n",
        "    else:\n",
        "      history = train_model(model, loss, train_dataset, valid_dataset)\n",
        "      model.save_weights(weights_file)\n",
        "      plt.plot(history.history['loss'])\n",
        "      plt.plot(history.history['val_loss'])\n",
        "      plt.ylabel('Loss')\n",
        "      plt.xlabel('Epoch')\n",
        "      plt.legend(['Train', 'Valid'], loc='upper right')\n",
        "      plt.show() "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpFpu5bZeYj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44a4d016-78bf-4119-d356-a07721e06c0e"
      },
      "source": [
        "train_ensemble(models_bin, keras.losses.BinaryCrossentropy,\n",
        "               train_dataset, valid_dataset)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restoring model weights from 28323f803767caeb2261fa7304685acc\n",
            "Restoring model weights from 3a120eaa0ec426481f89827dfc4a2782\n",
            "Restoring model weights from f6540761d812702d3bb4466310e20b93\n",
            "Restoring model weights from 4b4319045000911ff374050fa7882570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqEEKnoNq2eL"
      },
      "source": [
        "bin_ens = build_ensemble(models=models_bin, activation='linear')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dtmhSipt8iJ"
      },
      "source": [
        "def evaluate_ensemble(models, test_dataset, valid_dataset):\n",
        "  history = []\n",
        "  for model in models:\n",
        "    o = model.output_shape[-1]   \n",
        "    d = lambda x: np.argmax(x, -1) if o > 1 else x.squeeze(-1) > 0\n",
        "    pred = d(model.predict(test_dataset.batch(512)))\n",
        "    history.append(np.sum(pred != list(test_dataset.map(lambda x, y: y))))\n",
        "    pred = d(model.predict(valid_dataset.batch(512)))\n",
        "    history.append(np.sum(pred != list(valid_dataset.map(lambda x, y: y))))\n",
        "  plt.xlim(-0.6, len(history)/2 - 0.4)\n",
        "  plt.bar(np.arange(len(history)/2) - 0.2, history[::2], 0.4)\n",
        "  plt.bar(np.arange(len(history)/2) + 0.2, history[1::2], 0.4)\n",
        "  return np.array(history).reshape(-1, 2).tolist()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF0bF7Ro6Jg4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "4c72a764-22cc-4223-bbca-49d71bbc2aff"
      },
      "source": [
        "evaluate_ensemble(models_bin + (bin_ens,), test_dataset, valid_dataset)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[15, 12], [17, 10], [17, 10], [14, 7], [11, 9]]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 936x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSCsLW7940Og",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "867ce7c6-daa9-460f-982d-ba393fd5f9f4"
      },
      "source": [
        "train_dataset, test_dataset, valid_dataset = tfds.load(\n",
        "    name='my_dataset', split=['train', 'test', 'valid'],\n",
        "    data_dir='gs://tfds-gsc-1.appspot.com',\n",
        "    as_supervised=True)\n",
        "train_dataset.cardinality().numpy()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1095480"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ll-WLEB0yGj"
      },
      "source": [
        "train_dataset = train_dataset.map(lambda x, y: (x[1:-1], y)).cache()\n",
        "test_dataset  = test_dataset.map(lambda x, y:  (x[1:-1], y)).cache()\n",
        "valid_dataset = valid_dataset.map(lambda x, y: (x[1:-1], y)).cache()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBdK_jqApFOa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "f62b11cf-d6f9-47a2-c703-47af5d75bf7f"
      },
      "source": [
        "evaluate_ensemble(models_bin + (bin_ens,),\n",
        "                  test_dataset.map(lambda x, y: [x, y < 10]),\n",
        "                  valid_dataset.map(lambda x, y: [x, y < 10]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[312, 303], [299, 287], [316, 295], [315, 298], [309, 293]]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 936x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq1S896nzwsY"
      },
      "source": [
        "models_builders_cat = (\n",
        "  (build_model, 'leaky_relu', keras.layers.MaxPool1D, 12,     128),\n",
        "  (build_model, 'relu',       keras.layers.AvgPool1D, 12,     128),\n",
        "  (build_model, 'relu6',      keras.layers.MaxPool1D, 12, 64, 128),\n",
        "  (build_model, 'elu',        keras.layers.AvgPool1D, 12, 64, 128),\n",
        ")\n",
        "models_cat = build_ensemble(builders=models_builders_cat)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_Ky6M9bzwsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3a0d73c-2863-44b5-f782-b44c225118ad"
      },
      "source": [
        "train_ensemble(models_cat, keras.losses.SparseCategoricalCrossentropy,\n",
        "               train_dataset, valid_dataset)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restoring model weights from e7e8bec4019f75b50021d0976ccd6c38\n",
            "Restoring model weights from 77ea91aa526708b463ab0a466befa487\n",
            "Restoring model weights from b86d75d1480db917ab133cc6027564c0\n",
            "Restoring model weights from 76ae1b4ae2ff082f3154066d5e36578e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOSh6sFK_rJM"
      },
      "source": [
        "cat_ens = build_ensemble(models=models_cat, activation='softmax')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyFS6NeSK3jq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed45bafc-48a3-4872-b69c-6852789f3807"
      },
      "source": [
        "ens = build_ensemble(models=[bin_ens, cat_ens])\n",
        "ens.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 47, 13)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_6 (Functional)            (None, 12)           830896      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_5 (Functional)            (None, 1)            825220      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem (Slici (None,)              0           model_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_1 (Sli (None,)              0           model_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.squeeze (TFOpLambd (None,)              0           model_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.greater_1 (TFOpLambda)  (None,)              0           tf.__operators__.getitem[0][0]   \n",
            "                                                                 tf.__operators__.getitem_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.greater (TFOpLambda)    (None,)              0           tf.compat.v1.squeeze[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax (TFOpLambda)     (None,)              0           model_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.where (TFOpLambda)           (None,)              0           tf.math.greater_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.where_1 (TFOpLambda)         (None,)              0           tf.math.greater[0][0]            \n",
            "                                                                 tf.math.argmax[0][0]             \n",
            "                                                                 tf.where[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.one_hot (TFOpLambda)         (None, 12)           0           tf.where_1[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,656,116\n",
            "Trainable params: 1,639,220\n",
            "Non-trainable params: 16,896\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_ADol7Qo07G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "1e796784-4d5f-4293-a64d-64324edc2f0b"
      },
      "source": [
        "evaluate_ensemble(models_cat + (cat_ens, ens,),\n",
        "                  test_dataset, valid_dataset)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[45, 27], [48, 27], [51, 23], [42, 30], [40, 27], [59, 33]]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 936x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82FeO4px4htt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda79a2f-2420-491f-9eeb-f762442101d8"
      },
      "source": [
        "matrix = tf.math.confusion_matrix(\n",
        "  list(test_dataset.map(lambda x, y: y)),\n",
        "  ens.predict(test_dataset.batch(4096)).argmax(axis=-1)).numpy()\n",
        "for r in matrix:\n",
        "  l = np.sum(r)\n",
        "  for i in r:\n",
        "    print(('%.2f' % (i / l)).replace('0.00', ' .  '), end = ' ')\n",
        "  print(\"|\", l)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.99  .    .    .    .    .    .   0.01  .    .    .    .   | 315\n",
            " .   0.97  .    .    .    .    .    .    .   0.01 0.01  .   | 309\n",
            " .    .   0.99  .    .    .    .    .    .    .   0.01  .   | 304\n",
            " .    .    .   0.97  .    .    .    .    .    .   0.03  .   | 304\n",
            " .    .    .    .   0.99  .    .    .    .    .   0.01  .   | 310\n",
            " .    .    .    .    .   0.97  .    .    .    .   0.02  .   | 336\n",
            " .    .    .    .    .    .   1.00  .    .    .    .    .   | 249\n",
            " .    .    .    .    .    .    .   1.00  .    .    .    .   | 306\n",
            " .    .    .    .    .    .    .    .   1.00  .    .    .   | 298\n",
            " .    .    .    .    .   0.01  .    .    .   0.98 0.01  .   | 312\n",
            " .   0.01  .   0.01 0.01  .    .    .    .    .   0.97  .   | 365\n",
            " .    .    .    .    .    .    .    .    .    .    .   1.00 | 365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9xA2CduCZNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e37bc66f-24a6-49e3-ca53-ab61fdae606f"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(ens)\n",
        "tflite_model = converter.convert()\n",
        "with open(\"_2ecnn47.tflite\", \"wb\") as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmptnkb9rqi/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmptnkb9rqi/assets\n",
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3bNp1IZCZ_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae1c44ef-26c1-4db5-cdca-f232ea801385"
      },
      "source": [
        "!md5sum '_2ecnn47.tflite'\n",
        "!mv '_2ecnn47.tflite' \"$KERAS_MODELS_ABSOLUTE_PATH\""
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f85c06ab82059f35b7b622c42a690247  _2ecnn47.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffiCBasYWAs9"
      },
      "source": [
        "def transfer_weights(dest, src):\n",
        "  for dest, src in zip(dest, src):\n",
        "    for layer in dest.layers:\n",
        "      if layer.get_weights():\n",
        "        print(\"Transfer weights for layer {}\".format(layer.name))\n",
        "        layer.set_weights(src.get_layer(name=layer.name).get_weights())"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfQIakeYV6oD",
        "outputId": "6793fc01-37b5-47ca-8c39-347b0230e726"
      },
      "source": [
        "models_bin_str = build_ensemble(builders=models_builders_bin, streaming=True)\n",
        "transfer_weights(models_bin_str, models_bin)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer dense_2\n",
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer dense_2\n",
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_7\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer conv1d_5\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_2\n",
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_7\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer conv1d_5\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C51RqntYPEx",
        "outputId": "4f323135-aa47-4dee-9473-f7ccf236f61c"
      },
      "source": [
        "models_cat_str = build_ensemble(builders=models_builders_cat, streaming=True)\n",
        "transfer_weights(models_cat_str, models_cat)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer dense_2\n",
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer dense_2\n",
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_7\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer conv1d_5\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_2\n",
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_7\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer conv1d_5\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMf3QNgCEYwc",
        "outputId": "713cf00f-f229-4b8d-8396-1ec9c6b9ae78"
      },
      "source": [
        "bin_str_ens = build_ensemble(models=models_bin_str, activation='linear', streaming=True)\n",
        "cat_str_ens = build_ensemble(models=models_cat_str, activation='softmax', streaming=True)\n",
        "ens_str = build_ensemble(models=[bin_str_ens, cat_str_ens], streaming=True)\n",
        "ens_str.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_49 (InputLayer)           [(None, 1, 13)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_70 (InputLayer)           [(None, 2, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_71 (InputLayer)           [(None, 3, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_72 (InputLayer)           [(None, 5, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_73 (InputLayer)           [(None, 9, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_74 (InputLayer)           [(None, 32, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_75 (InputLayer)           [(None, 2, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_76 (InputLayer)           [(None, 3, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_77 (InputLayer)           [(None, 5, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_78 (InputLayer)           [(None, 9, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_79 (InputLayer)           [(None, 32, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_80 (InputLayer)           [(None, 2, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_81 (InputLayer)           [(None, 3, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_82 (InputLayer)           [(None, 5, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_83 (InputLayer)           [(None, 9, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_84 (InputLayer)           [(None, 32, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_85 (InputLayer)           [(None, 2, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_86 (InputLayer)           [(None, 3, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_87 (InputLayer)           [(None, 5, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_88 (InputLayer)           [(None, 9, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_89 (InputLayer)           [(None, 32, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_50 (InputLayer)           [(None, 2, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_51 (InputLayer)           [(None, 3, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_52 (InputLayer)           [(None, 5, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_53 (InputLayer)           [(None, 9, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_54 (InputLayer)           [(None, 32, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_55 (InputLayer)           [(None, 2, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_56 (InputLayer)           [(None, 3, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_57 (InputLayer)           [(None, 5, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_58 (InputLayer)           [(None, 9, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_59 (InputLayer)           [(None, 32, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_60 (InputLayer)           [(None, 2, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_61 (InputLayer)           [(None, 3, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_62 (InputLayer)           [(None, 5, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_63 (InputLayer)           [(None, 9, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_64 (InputLayer)           [(None, 32, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_65 (InputLayer)           [(None, 2, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_66 (InputLayer)           [(None, 3, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_67 (InputLayer)           [(None, 5, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_68 (InputLayer)           [(None, 9, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_69 (InputLayer)           [(None, 32, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_11 (Functional)           [(None, 12), (None,  830896      input_49[0][0]                   \n",
            "                                                                 input_70[0][0]                   \n",
            "                                                                 input_71[0][0]                   \n",
            "                                                                 input_72[0][0]                   \n",
            "                                                                 input_73[0][0]                   \n",
            "                                                                 input_74[0][0]                   \n",
            "                                                                 input_75[0][0]                   \n",
            "                                                                 input_76[0][0]                   \n",
            "                                                                 input_77[0][0]                   \n",
            "                                                                 input_78[0][0]                   \n",
            "                                                                 input_79[0][0]                   \n",
            "                                                                 input_80[0][0]                   \n",
            "                                                                 input_81[0][0]                   \n",
            "                                                                 input_82[0][0]                   \n",
            "                                                                 input_83[0][0]                   \n",
            "                                                                 input_84[0][0]                   \n",
            "                                                                 input_85[0][0]                   \n",
            "                                                                 input_86[0][0]                   \n",
            "                                                                 input_87[0][0]                   \n",
            "                                                                 input_88[0][0]                   \n",
            "                                                                 input_89[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_10 (Functional)           [(None, 1), (None, 1 825220      input_49[0][0]                   \n",
            "                                                                 input_50[0][0]                   \n",
            "                                                                 input_51[0][0]                   \n",
            "                                                                 input_52[0][0]                   \n",
            "                                                                 input_53[0][0]                   \n",
            "                                                                 input_54[0][0]                   \n",
            "                                                                 input_55[0][0]                   \n",
            "                                                                 input_56[0][0]                   \n",
            "                                                                 input_57[0][0]                   \n",
            "                                                                 input_58[0][0]                   \n",
            "                                                                 input_59[0][0]                   \n",
            "                                                                 input_60[0][0]                   \n",
            "                                                                 input_61[0][0]                   \n",
            "                                                                 input_62[0][0]                   \n",
            "                                                                 input_63[0][0]                   \n",
            "                                                                 input_64[0][0]                   \n",
            "                                                                 input_65[0][0]                   \n",
            "                                                                 input_66[0][0]                   \n",
            "                                                                 input_67[0][0]                   \n",
            "                                                                 input_68[0][0]                   \n",
            "                                                                 input_69[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem (Slici (None,)              0           model_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_1 (Sli (None,)              0           model_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.squeeze (TFOpLambd (None,)              0           model_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.greater_1 (TFOpLambda)  (None,)              0           tf.__operators__.getitem[0][0]   \n",
            "                                                                 tf.__operators__.getitem_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.greater (TFOpLambda)    (None,)              0           tf.compat.v1.squeeze[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax (TFOpLambda)     (None,)              0           model_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.where (TFOpLambda)           (None,)              0           tf.math.greater_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.where_1 (TFOpLambda)         (None,)              0           tf.math.greater[0][0]            \n",
            "                                                                 tf.math.argmax[0][0]             \n",
            "                                                                 tf.where[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.one_hot (TFOpLambda)         (None, 12)           0           tf.where_1[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,656,116\n",
            "Trainable params: 1,639,220\n",
            "Non-trainable params: 16,896\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_osefPcMYmgD",
        "outputId": "cddf9fff-39bb-4d18-febc-42e04853ee84"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(ens_str)\n",
        "tflite_model = converter.convert()\n",
        "with open(\"2ecnn13.tflite\", \"wb\") as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp836r2rvf/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp836r2rvf/assets\n",
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkxrCu4kYyFC",
        "outputId": "20fef3ba-bf8e-4755-fb6e-6c4c93ad1fc1"
      },
      "source": [
        "!md5sum '2ecnn13.tflite'\n",
        "!mv '2ecnn13.tflite' \"$KERAS_MODELS_ABSOLUTE_PATH\""
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a0f735910f0c4e7b6f9e995cbd806824  2ecnn13.tflite\n"
          ]
        }
      ]
    }
  ]
}