{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M09OlPRpDRSh"
      },
      "outputs": [],
      "source": [
        "KERAS_MODELS_ABSOLUTE_PATH = '/content/gdrive/My Drive/3ecnn13'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKHNt4dNhRMF",
        "outputId": "68ced09d-c295-4906-cd25-0cec8cf67d71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UutF8PBu-oO",
        "outputId": "1a79be72-45b0-4473-ad7d-8d38c665805b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Datasets: 4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -qq tensorflow-datasets -U\n",
        "!tfds --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T3UOLCpGUmg",
        "outputId": "b51b731f-9883-4e87-91b9-ca23608bf8de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "print(tf.__version__)\n",
        "plt.rc('figure', figsize=(13, 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fubso462-iVr"
      },
      "outputs": [],
      "source": [
        "if not tf.io.gfile.exists(KERAS_MODELS_ABSOLUTE_PATH):\n",
        "  print('You should create', KERAS_MODELS_ABSOLUTE_PATH, 'directory manually')\n",
        "  assert False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFFScd8fBIKk",
        "outputId": "73d53a8e-614e-400e-9ef4-8e061145530d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.9.156.106:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.9.156.106:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n",
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ],
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Xcj5MHTAKYwv"
      },
      "outputs": [],
      "source": [
        "def spectrogram_masking(spectrogram, dim=1, masks_number=2, mask_max_size=5):\n",
        "  \"\"\"Spectrogram masking on frequency or time dimension.\n",
        "  Args:\n",
        "    spectrogram: Input spectrum [batch, time, frequency]\n",
        "    dim: dimension on which masking will be applied: 1 - time; 2 - frequency\n",
        "    masks_number: number of masks\n",
        "    mask_max_size: mask max size\n",
        "  Returns:\n",
        "    masked spectrogram\n",
        "  \"\"\"\n",
        "  if dim not in (1, 2):\n",
        "    raise ValueError('Wrong dim value: %d' % dim)\n",
        "  input_shape = spectrogram.shape\n",
        "  time_size, frequency_size = input_shape[1:3]\n",
        "  dim_size = input_shape[dim]  # size of dimension on which mask is applied\n",
        "  stripe_shape = [1, time_size, frequency_size]\n",
        "  for _ in range(masks_number):\n",
        "    mask_end = tf.random.uniform([], 0, mask_max_size, tf.int32)\n",
        "    mask_start = tf.random.uniform([], 0, dim_size - mask_end, tf.int32)\n",
        "\n",
        "    # initialize stripes with stripe_shape\n",
        "    stripe_ones_left = list(stripe_shape)\n",
        "    stripe_zeros_center = list(stripe_shape)\n",
        "    stripe_ones_right = list(stripe_shape)\n",
        "\n",
        "    # update stripes dim\n",
        "    stripe_ones_left[dim] = dim_size - mask_start - mask_end\n",
        "    stripe_zeros_center[dim] = mask_end\n",
        "    stripe_ones_right[dim] = mask_start\n",
        "\n",
        "    # generate mask\n",
        "    mask = tf.concat((\n",
        "        tf.ones(stripe_ones_left, spectrogram.dtype),\n",
        "        tf.zeros(stripe_zeros_center, spectrogram.dtype),\n",
        "        tf.ones(stripe_ones_right, spectrogram.dtype),\n",
        "    ), dim)\n",
        "    spectrogram = spectrogram * mask\n",
        "  return spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-WXRm7NyAtks"
      },
      "outputs": [],
      "source": [
        "def streaming_input_output(streaming, t, inputs, otputs, x):\n",
        "  if streaming:\n",
        "    otputs.append(x)\n",
        "    x = keras.Input(shape=[t] + x.shape[2:])\n",
        "    inputs.append(x)\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vP5AfeDYPYK4"
      },
      "outputs": [],
      "source": [
        "def build_model(name, in_shape, activation, pooling, out_shape, *in_steps):\n",
        "\n",
        "  # resetting the layer name generation counter\n",
        "  keras.backend.clear_session()\n",
        "\n",
        "  inputs, outputs = [], []\n",
        "  streaming = in_shape[0] == 1\n",
        "\n",
        "  x = x_in = keras.Input(shape=in_shape)\n",
        "\n",
        "  for i in in_steps:\n",
        "    x = keras.layers.Conv1D(i, 1, use_bias=False)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Activation(activation)(x)\n",
        "    x = keras.layers.SpatialDropout1D(i / 1280.0)(x)\n",
        "\n",
        "  for i in range(4):\n",
        "    x = streaming_input_output(streaming, 1 + 2**i, inputs, outputs, x)\n",
        "    x = keras.layers.Conv1D(x.shape[-1], 2,\n",
        "                            dilation_rate=2**i, use_bias=False)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Activation(activation)(x)\n",
        "    x = keras.layers.SpatialDropout1D(x.shape[-1] / 1280.0)(x)\n",
        "\n",
        "  x = streaming_input_output(streaming, 32, inputs, outputs, x)\n",
        "  x = pooling(x.shape[1])(x)\n",
        "  x = keras.layers.Flatten()(x)\n",
        "\n",
        "  for i in x.shape[-1] * np.array([2, 1]):\n",
        "    x = keras.layers.Dense(i, use_bias=False)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Activation(activation)(x)\n",
        "    x = keras.layers.Dropout(i / 1280.0)(x)\n",
        "\n",
        "  x = keras.layers.Dense(out_shape)(x)\n",
        "  return keras.Model([x_in] + inputs, [x] + outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "E84wnQt1s_VY"
      },
      "outputs": [],
      "source": [
        "def build_ensemble(name='second_ensemble', builders=None,\n",
        "                   models=None, activation=None, streaming=False):\n",
        "  in_shape = (1 if streaming else 47, 13)\n",
        "  if models:\n",
        "    x_in = keras.Input(shape=in_shape)\n",
        "    x = [keras.Model(m.inputs, m.outputs) for m in models]\n",
        "    if streaming:\n",
        "      inputs = [[keras.Input(e.shape[1:]) for e in m.inputs[1:]] for m in x]\n",
        "      x = [e([x_in] + i) for e, i in zip(x, inputs)]\n",
        "      inputs = [i for e in inputs for i in e]\n",
        "      outputs = [i for e in x for i in e[1:]]\n",
        "      x = [e[0] for e in x]\n",
        "    else:\n",
        "      inputs, outputs = [], []\n",
        "      x = [e(x_in) for e in x]\n",
        "    if activation:\n",
        "      x = [keras.layers.Activation(activation)(e) for e in x]\n",
        "      x = keras.layers.Average()(x)\n",
        "    else:\n",
        "      b, c = x\n",
        "      b = tf.squeeze(b, -1)\n",
        "      b = tf.greater(b, 2) # threshold\n",
        "      u = tf.greater(c[:,10], c[:,11])\n",
        "      u = tf.where(u, 10, 11)\n",
        "      x = tf.where(b, tf.argmax(c, -1, u.dtype), u)\n",
        "      x = tf.one_hot(x, 12)\n",
        "    return keras.Model([x_in] + inputs, [x] + outputs)\n",
        "  else:\n",
        "    return tuple(b(name, in_shape, *a) for b, *a in builders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "R6Nk8XnPozIq"
      },
      "outputs": [],
      "source": [
        "models_builders_bin = (\n",
        "  (build_model, 'leaky_relu', keras.layers.MaxPool1D, 1,     128),\n",
        "  (build_model, 'relu',       keras.layers.AvgPool1D, 1,     128),\n",
        "  (build_model, 'relu6',      keras.layers.MaxPool1D, 1, 64, 128),\n",
        "  (build_model, 'elu',        keras.layers.AvgPool1D, 1, 64, 128),\n",
        ")\n",
        "models_bin_1 = build_ensemble(builders=models_builders_bin)\n",
        "models_bin_2 = build_ensemble('third_ensemble', models_builders_bin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "x5m9wOJwCxxA"
      },
      "outputs": [],
      "source": [
        "def train_model(model, loss, train_dataset, valid_dataset):\n",
        "\n",
        "  with strategy.scope():\n",
        "    tpu_model = keras.Model.from_config(model.get_config())\n",
        "    tpu_model.compile(\n",
        "      loss=loss(from_logits=True),\n",
        "      optimizer=keras.optimizers.Adam(),\n",
        "      metrics=['accuracy'])\n",
        "\n",
        "  early_stopping = keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        verbose=1,\n",
        "        patience=100,\n",
        "        restore_best_weights=True)\n",
        "\n",
        "  tpu_num_cores = resolver.get_tpu_system_metadata().num_cores\n",
        "\n",
        "  train_batch = train_dataset.shuffle(train_dataset.cardinality())\n",
        "  train_batch = train_batch.batch(tpu_num_cores * 64, drop_remainder=True)\n",
        "  train_batch = train_batch.map(lambda x, y: (spectrogram_masking(x, 1, 3, 5), y))\n",
        "  train_batch = train_batch.map(lambda x, y: (spectrogram_masking(x, 2, 2, 2), y))\n",
        "  train_batch = train_batch.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  valid_batch = valid_dataset.batch(8, drop_remainder=True)\n",
        "  valid_batch = valid_batch.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  # plt.imshow(list(train_batch.take(1))[0][0][0].numpy().T)\n",
        "  # plt.show()\n",
        "\n",
        "  history = tpu_model.fit(train_batch,\n",
        "                          validation_data=valid_batch,\n",
        "                          callbacks=[early_stopping],\n",
        "                          verbose=2,\n",
        "                          epochs=1000) # play with google colab time limit\n",
        "\n",
        "  model.set_weights(early_stopping.best_weights)\n",
        "  return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UDdJ8Q2Tx49J"
      },
      "outputs": [],
      "source": [
        "def train_ensemble(ensemble_models, loss, train_dataset, valid_dataset):\n",
        "\n",
        "  for model in ensemble_models:\n",
        "    md5 = str(model.get_config())\n",
        "    md5 = !echo \"$md5\" | md5sum\n",
        "    md5 = md5[0].split()[0]\n",
        "    weights_file = \"%s/%s.h5\" % (KERAS_MODELS_ABSOLUTE_PATH, md5)\n",
        "\n",
        "    if tf.io.gfile.exists(weights_file):\n",
        "      print('Restoring model weights from', md5)\n",
        "      model.load_weights(weights_file)\n",
        "    else:\n",
        "      history = train_model(model, loss, train_dataset, valid_dataset)\n",
        "      model.save_weights(weights_file)\n",
        "      plt.plot(history.history['loss'])\n",
        "      plt.plot(history.history['val_loss'])\n",
        "      plt.ylabel('Loss')\n",
        "      plt.xlabel('Epoch')\n",
        "      plt.legend(['Train', 'Valid'], loc='upper right')\n",
        "      plt.show() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9dtmhSipt8iJ"
      },
      "outputs": [],
      "source": [
        "def evaluate_ensemble(models, test_dataset, valid_dataset):\n",
        "  history = []\n",
        "  for model in models:\n",
        "    o = model.output_shape[-1]   \n",
        "    d = lambda x: np.argmax(x, -1) if o > 1 else x.squeeze(-1) > 0\n",
        "    pred = d(model.predict(test_dataset.batch(512)))\n",
        "    history.append(np.sum(pred != list(test_dataset.map(lambda x, y: y))))\n",
        "    pred = d(model.predict(valid_dataset.batch(512)))\n",
        "    history.append(np.sum(pred != list(valid_dataset.map(lambda x, y: y))))\n",
        "  plt.xlim(-0.6, len(history)/2 - 0.4)\n",
        "  plt.bar(np.arange(len(history)/2) - 0.2, history[::2], 0.4)\n",
        "  plt.bar(np.arange(len(history)/2) + 0.2, history[1::2], 0.4)\n",
        "  return np.array(history).reshape(-1, 2).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQC5dJmvnlm0",
        "outputId": "237850d4-aee9-4fda-a0e8-b1f63e65dd8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1825800"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "(train_dataset, test_dataset, valid_dataset), info = tfds.load(\n",
        "    name='my_dataset', split=['train', 'test', 'valid'],\n",
        "    data_dir='gs://tfds-musan-1.appspot.com',\n",
        "    as_supervised=True, try_gcs=True, with_info=True)\n",
        "assert info.homepage == 'https://github.com/42io/dataset/tree/master/openslr_musan'\n",
        "train_dataset.cardinality().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AODNDf4J-fVh"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.map(lambda x, y: (x[1:-1], y))\n",
        "test_dataset  = test_dataset.map(lambda x, y:  (x[1:-1], y))\n",
        "valid_dataset = valid_dataset.map(lambda x, y: (x[1:-1], y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpFpu5bZeYj4",
        "outputId": "e31ed1ff-8cd2-40f2-fd62-7528a93e7f8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restoring model weights from 28323f803767caeb2261fa7304685acc\n",
            "Restoring model weights from 3a120eaa0ec426481f89827dfc4a2782\n",
            "Restoring model weights from f6540761d812702d3bb4466310e20b93\n",
            "Restoring model weights from 4b4319045000911ff374050fa7882570\n"
          ]
        }
      ],
      "source": [
        "train_ensemble(models_bin_1, keras.losses.BinaryCrossentropy,\n",
        "               train_dataset, valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pqEEKnoNq2eL"
      },
      "outputs": [],
      "source": [
        "bin_ens = build_ensemble(models=models_bin_1, activation='linear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Dtu_dH7nHDux",
        "outputId": "4d20fa22-2d41-4079-d6ce-fac13c1c63c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[15, 12], [17, 10], [17, 10], [14, 7], [11, 9]]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 936x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "evaluate_ensemble(models_bin_1 + (bin_ens,), test_dataset, valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vprCFCk6GYvD",
        "outputId": "2520eb8f-9295-4e03-a6c8-f708aaf603aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1825800"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "(train_dataset, test_dataset, valid_dataset), info = tfds.load(\n",
        "    name='my_dataset', split=['train', 'test', 'valid'],\n",
        "    data_dir='gs://tfds-libri-1.appspot.com',\n",
        "    as_supervised=True, try_gcs=True, with_info=True)\n",
        "assert info.homepage == 'https://github.com/42io/dataset/tree/master/openslr_libri'\n",
        "train_dataset.cardinality().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-15DPRVX8TDA"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.map(lambda x, y: (x[1:-1], y))\n",
        "test_dataset  = test_dataset.map(lambda x, y:  (x[1:-1], y))\n",
        "valid_dataset = valid_dataset.map(lambda x, y: (x[1:-1], y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCSw-N-_Gnjo",
        "outputId": "25bb1386-c8e0-4d5b-f1c7-028cc60aef00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restoring model weights from 4b65b86fea1e055801112be26e5f0b56\n",
            "Restoring model weights from fff40393ef87e68fa02c4cfd150f963e\n",
            "Restoring model weights from 79a5564878f3fabe69c4efd2471c5211\n",
            "Restoring model weights from 2743c293aaab27294d461206e5b2b0da\n"
          ]
        }
      ],
      "source": [
        "train_ensemble(models_bin_2, keras.losses.BinaryCrossentropy,\n",
        "               train_dataset, valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0Ryn9v8dNdJs"
      },
      "outputs": [],
      "source": [
        "bin_ens = build_ensemble(models=models_bin_2, activation='linear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xBHI-MGXNdJt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "6b55f0be-1ae5-43c7-8783-9bdc29068a13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[26, 18], [26, 14], [20, 16], [28, 17], [22, 15]]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 936x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "evaluate_ensemble(models_bin_2 + (bin_ens,), test_dataset, valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qSCsLW7940Og",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5734c6f-ab7c-4a5d-8e98-cf5eddba9024"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1095480"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "(train_dataset, test_dataset, valid_dataset), info = tfds.load(\n",
        "    name='my_dataset', split=['train', 'test', 'valid'],\n",
        "    data_dir='gs://tfds-gsc-1.appspot.com',\n",
        "    as_supervised=True, try_gcs=True, with_info=True)\n",
        "assert info.homepage == 'https://github.com/42io/dataset/tree/master/google_speech_commands'\n",
        "train_dataset.cardinality().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4Ll-WLEB0yGj"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.map(lambda x, y: (x[1:-1], y))\n",
        "test_dataset  = test_dataset.map(lambda x, y:  (x[1:-1], y))\n",
        "valid_dataset = valid_dataset.map(lambda x, y: (x[1:-1], y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "VjgLpU0nRYDA"
      },
      "outputs": [],
      "source": [
        "bin_ens = build_ensemble(models=models_bin_1 + models_bin_2, activation='linear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "RBdK_jqApFOa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "f60ca22a-c303-4571-96bc-4962d4668e23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[312, 303],\n",
              " [299, 287],\n",
              " [316, 295],\n",
              " [315, 298],\n",
              " [285, 271],\n",
              " [273, 245],\n",
              " [265, 246],\n",
              " [307, 278],\n",
              " [289, 278]]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 936x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "evaluate_ensemble(models_bin_1 + models_bin_2 + (bin_ens,),\n",
        "                  test_dataset.map(lambda x, y: [x, y < 10]),\n",
        "                  valid_dataset.map(lambda x, y: [x, y < 10]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "sq1S896nzwsY"
      },
      "outputs": [],
      "source": [
        "models_builders_cat = (\n",
        "  (build_model, 'leaky_relu', keras.layers.MaxPool1D, 12,     128),\n",
        "  (build_model, 'relu',       keras.layers.AvgPool1D, 12,     128),\n",
        "  (build_model, 'relu6',      keras.layers.MaxPool1D, 12, 64, 128),\n",
        "  (build_model, 'elu',        keras.layers.AvgPool1D, 12, 64, 128),\n",
        ")\n",
        "models_cat = build_ensemble(builders=models_builders_cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "5_Ky6M9bzwsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9fe6ac0-3f90-4ef9-dc84-8c906766d604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restoring model weights from e7e8bec4019f75b50021d0976ccd6c38\n",
            "Restoring model weights from 77ea91aa526708b463ab0a466befa487\n",
            "Restoring model weights from b86d75d1480db917ab133cc6027564c0\n",
            "Restoring model weights from 76ae1b4ae2ff082f3154066d5e36578e\n"
          ]
        }
      ],
      "source": [
        "train_ensemble(models_cat, keras.losses.SparseCategoricalCrossentropy,\n",
        "               train_dataset, valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "dOSh6sFK_rJM"
      },
      "outputs": [],
      "source": [
        "cat_ens = build_ensemble(models=models_cat, activation='softmax')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "AyFS6NeSK3jq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f57357e7-14da-4914-b5f1-de0c72bf202e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 47, 13)]     0           []                               \n",
            "                                                                                                  \n",
            " model_6 (Functional)           (None, 12)           830896      ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " model_5 (Functional)           (None, 1)            1650440     ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None,)             0           ['model_6[0][0]']                \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None,)             0           ['model_6[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.compat.v1.squeeze (TFOpLamb  (None,)             0           ['model_5[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.greater_1 (TFOpLambda)  (None,)             0           ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 , 'tf.__operators__.getitem_1[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.math.greater (TFOpLambda)   (None,)              0           ['tf.compat.v1.squeeze[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.argmax (TFOpLambda)    (None,)              0           ['model_6[0][0]']                \n",
            "                                                                                                  \n",
            " tf.where (TFOpLambda)          (None,)              0           ['tf.math.greater_1[0][0]']      \n",
            "                                                                                                  \n",
            " tf.where_1 (TFOpLambda)        (None,)              0           ['tf.math.greater[0][0]',        \n",
            "                                                                  'tf.math.argmax[0][0]',         \n",
            "                                                                  'tf.where[0][0]']               \n",
            "                                                                                                  \n",
            " tf.one_hot (TFOpLambda)        (None, 12)           0           ['tf.where_1[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,481,336\n",
            "Trainable params: 2,455,992\n",
            "Non-trainable params: 25,344\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "ens = build_ensemble(models=[bin_ens, cat_ens])\n",
        "ens.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Q_ADol7Qo07G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "91428c4c-4bd7-4927-bde4-146e218d7ade"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[45, 27], [48, 27], [51, 23], [42, 30], [40, 27], [55, 33]]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 936x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "evaluate_ensemble(models_cat + (cat_ens, ens,),\n",
        "                  test_dataset, valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "82FeO4px4htt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99af996d-a625-49c6-e92f-37fadd0aa3d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.99  .    .    .    .    .    .   0.01  .    .    .    .   | 315\n",
            " .   0.97  .    .    .    .    .    .    .   0.01 0.01  .   | 309\n",
            " .    .   0.99  .    .    .    .    .    .    .   0.01  .   | 304\n",
            " .    .    .   0.98  .    .    .    .    .    .   0.02  .   | 304\n",
            " .    .    .    .   0.99  .    .    .    .    .   0.01  .   | 310\n",
            " .    .    .    .    .   0.98  .    .    .    .   0.01  .   | 336\n",
            " .    .    .    .    .    .   0.99  .    .    .    .    .   | 249\n",
            " .    .    .    .    .    .    .   1.00  .    .    .    .   | 306\n",
            " .    .    .    .    .    .    .    .   0.99  .   0.01  .   | 298\n",
            " .    .    .    .    .   0.01  .    .    .   0.98 0.01  .   | 312\n",
            " .   0.01  .   0.01 0.01  .    .    .    .    .   0.97  .   | 365\n",
            " .    .    .    .    .    .    .    .    .    .    .   1.00 | 365\n"
          ]
        }
      ],
      "source": [
        "matrix = tf.math.confusion_matrix(\n",
        "  list(test_dataset.map(lambda x, y: y)),\n",
        "  ens.predict(test_dataset.batch(4096)).argmax(axis=-1)).numpy()\n",
        "for r in matrix:\n",
        "  l = np.sum(r)\n",
        "  for i in r:\n",
        "    print(('%.2f' % (i / l)).replace('0.00', ' .  '), end = ' ')\n",
        "  print(\"|\", l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Y9xA2CduCZNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e7ff627-6624-43ca-ba94-2801f2c03139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp83fxtjih/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp83fxtjih/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(ens)\n",
        "tflite_model = converter.convert()\n",
        "with open(\"_3ecnn47.tflite\", \"wb\") as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "u3bNp1IZCZ_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cbeaf4e-0f80-420d-d559-819e7a8df6a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abd1f8c35fcdedf08d2ed662e4066afd  _3ecnn47.tflite\n"
          ]
        }
      ],
      "source": [
        "!md5sum '_3ecnn47.tflite'\n",
        "!mv '_3ecnn47.tflite' \"$KERAS_MODELS_ABSOLUTE_PATH\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ffiCBasYWAs9"
      },
      "outputs": [],
      "source": [
        "def transfer_weights(dest, src):\n",
        "  for dest, src in zip(dest, src):\n",
        "    for layer in dest.layers:\n",
        "      if layer.get_weights():\n",
        "        print(\"Transfer weights for layer {}\".format(layer.name))\n",
        "        layer.set_weights(src.get_layer(name=layer.name).get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "HfQIakeYV6oD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53972134-90c5-4f78-dc2a-53e4f6b64ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer dense_2\n",
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer dense_2\n",
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_7\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer conv1d_5\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_2\n",
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_7\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer conv1d_5\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_2\n",
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer dense_2\n",
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer dense_2\n",
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_7\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer conv1d_5\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_2\n",
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_7\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer conv1d_5\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_2\n"
          ]
        }
      ],
      "source": [
        "models_bin_str = build_ensemble(builders=models_builders_bin, streaming=True)\n",
        "models_bin_str += build_ensemble(builders=models_builders_bin, streaming=True)\n",
        "transfer_weights(models_bin_str, models_bin_1 + models_bin_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5C51RqntYPEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ca9a3b-4ab6-44d0-f6c4-df5eab545d7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer dense_2\n",
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer dense_2\n",
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_7\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer conv1d_5\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_2\n",
            "Transfer weights for layer dense\n",
            "Transfer weights for layer batch_normalization_6\n",
            "Transfer weights for layer conv1d\n",
            "Transfer weights for layer batch_normalization\n",
            "Transfer weights for layer dense_1\n",
            "Transfer weights for layer batch_normalization_7\n",
            "Transfer weights for layer conv1d_1\n",
            "Transfer weights for layer conv1d_2\n",
            "Transfer weights for layer conv1d_3\n",
            "Transfer weights for layer conv1d_4\n",
            "Transfer weights for layer conv1d_5\n",
            "Transfer weights for layer batch_normalization_1\n",
            "Transfer weights for layer batch_normalization_2\n",
            "Transfer weights for layer batch_normalization_3\n",
            "Transfer weights for layer batch_normalization_4\n",
            "Transfer weights for layer batch_normalization_5\n",
            "Transfer weights for layer dense_2\n"
          ]
        }
      ],
      "source": [
        "models_cat_str = build_ensemble(builders=models_builders_cat, streaming=True)\n",
        "transfer_weights(models_cat_str, models_cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "cMf3QNgCEYwc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1adf3c2d-cb77-48fc-acc3-da521f7888d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_69 (InputLayer)          [(None, 1, 13)]      0           []                               \n",
            "                                                                                                  \n",
            " input_110 (InputLayer)         [(None, 2, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_111 (InputLayer)         [(None, 3, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_112 (InputLayer)         [(None, 5, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_113 (InputLayer)         [(None, 9, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_114 (InputLayer)         [(None, 32, 128)]    0           []                               \n",
            "                                                                                                  \n",
            " input_115 (InputLayer)         [(None, 2, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_116 (InputLayer)         [(None, 3, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_117 (InputLayer)         [(None, 5, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_118 (InputLayer)         [(None, 9, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_119 (InputLayer)         [(None, 32, 128)]    0           []                               \n",
            "                                                                                                  \n",
            " input_120 (InputLayer)         [(None, 2, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_121 (InputLayer)         [(None, 3, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_122 (InputLayer)         [(None, 5, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_123 (InputLayer)         [(None, 9, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_124 (InputLayer)         [(None, 32, 128)]    0           []                               \n",
            "                                                                                                  \n",
            " input_125 (InputLayer)         [(None, 2, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_126 (InputLayer)         [(None, 3, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_127 (InputLayer)         [(None, 5, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_128 (InputLayer)         [(None, 9, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_129 (InputLayer)         [(None, 32, 128)]    0           []                               \n",
            "                                                                                                  \n",
            " input_70 (InputLayer)          [(None, 2, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_71 (InputLayer)          [(None, 3, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_72 (InputLayer)          [(None, 5, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_73 (InputLayer)          [(None, 9, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_74 (InputLayer)          [(None, 32, 128)]    0           []                               \n",
            "                                                                                                  \n",
            " input_75 (InputLayer)          [(None, 2, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_76 (InputLayer)          [(None, 3, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_77 (InputLayer)          [(None, 5, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_78 (InputLayer)          [(None, 9, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_79 (InputLayer)          [(None, 32, 128)]    0           []                               \n",
            "                                                                                                  \n",
            " input_80 (InputLayer)          [(None, 2, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_81 (InputLayer)          [(None, 3, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_82 (InputLayer)          [(None, 5, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_83 (InputLayer)          [(None, 9, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_84 (InputLayer)          [(None, 32, 128)]    0           []                               \n",
            "                                                                                                  \n",
            " input_85 (InputLayer)          [(None, 2, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_86 (InputLayer)          [(None, 3, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_87 (InputLayer)          [(None, 5, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_88 (InputLayer)          [(None, 9, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_89 (InputLayer)          [(None, 32, 128)]    0           []                               \n",
            "                                                                                                  \n",
            " input_90 (InputLayer)          [(None, 2, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_91 (InputLayer)          [(None, 3, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_92 (InputLayer)          [(None, 5, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_93 (InputLayer)          [(None, 9, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_94 (InputLayer)          [(None, 32, 128)]    0           []                               \n",
            "                                                                                                  \n",
            " input_95 (InputLayer)          [(None, 2, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_96 (InputLayer)          [(None, 3, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_97 (InputLayer)          [(None, 5, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_98 (InputLayer)          [(None, 9, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_99 (InputLayer)          [(None, 32, 128)]    0           []                               \n",
            "                                                                                                  \n",
            " input_100 (InputLayer)         [(None, 2, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_101 (InputLayer)         [(None, 3, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_102 (InputLayer)         [(None, 5, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_103 (InputLayer)         [(None, 9, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_104 (InputLayer)         [(None, 32, 128)]    0           []                               \n",
            "                                                                                                  \n",
            " input_105 (InputLayer)         [(None, 2, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_106 (InputLayer)         [(None, 3, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_107 (InputLayer)         [(None, 5, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_108 (InputLayer)         [(None, 9, 128)]     0           []                               \n",
            "                                                                                                  \n",
            " input_109 (InputLayer)         [(None, 32, 128)]    0           []                               \n",
            "                                                                                                  \n",
            " model_15 (Functional)          [(None, 12),         830896      ['input_69[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_110[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_111[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_112[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_113[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_114[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_115[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_116[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_117[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_118[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_119[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_120[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_121[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_122[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_123[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_124[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_125[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_126[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_127[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_128[0][0]',              \n",
            "                                 (None, 1, 128)]                  'input_129[0][0]']              \n",
            "                                                                                                  \n",
            " model_14 (Functional)          [(None, 1),          1650440     ['input_69[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_70[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_71[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_72[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_73[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_74[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_75[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_76[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_77[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_78[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_79[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_80[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_81[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_82[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_83[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_84[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_85[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_86[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_87[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_88[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_89[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_90[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_91[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_92[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_93[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_94[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_95[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_96[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_97[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_98[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_99[0][0]',               \n",
            "                                 (None, 1, 128),                  'input_100[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_101[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_102[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_103[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_104[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_105[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_106[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_107[0][0]',              \n",
            "                                 (None, 1, 128),                  'input_108[0][0]',              \n",
            "                                 (None, 1, 128)]                  'input_109[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None,)             0           ['model_15[0][0]']               \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None,)             0           ['model_15[0][0]']               \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.compat.v1.squeeze (TFOpLamb  (None,)             0           ['model_14[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.greater_1 (TFOpLambda)  (None,)             0           ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 , 'tf.__operators__.getitem_1[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.math.greater (TFOpLambda)   (None,)              0           ['tf.compat.v1.squeeze[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.argmax (TFOpLambda)    (None,)              0           ['model_15[0][0]']               \n",
            "                                                                                                  \n",
            " tf.where (TFOpLambda)          (None,)              0           ['tf.math.greater_1[0][0]']      \n",
            "                                                                                                  \n",
            " tf.where_1 (TFOpLambda)        (None,)              0           ['tf.math.greater[0][0]',        \n",
            "                                                                  'tf.math.argmax[0][0]',         \n",
            "                                                                  'tf.where[0][0]']               \n",
            "                                                                                                  \n",
            " tf.one_hot (TFOpLambda)        (None, 12)           0           ['tf.where_1[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,481,336\n",
            "Trainable params: 2,455,992\n",
            "Non-trainable params: 25,344\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "bin_str_ens = build_ensemble(models=models_bin_str, activation='linear', streaming=True)\n",
        "cat_str_ens = build_ensemble(models=models_cat_str, activation='softmax', streaming=True)\n",
        "ens_str = build_ensemble(models=[bin_str_ens, cat_str_ens], streaming=True)\n",
        "ens_str.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "_osefPcMYmgD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c74d69-cb34-4697-8f2f-a7ab67bf0d53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpmvdi33bl/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpmvdi33bl/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(ens_str)\n",
        "tflite_model = converter.convert()\n",
        "with open(\"3ecnn13.tflite\", \"wb\") as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "YkxrCu4kYyFC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4aad08b-bdbb-455f-8237-648e0164fb8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f8d577ed7f491e71e392df835677b08c  3ecnn13.tflite\n"
          ]
        }
      ],
      "source": [
        "!md5sum '3ecnn13.tflite'\n",
        "!mv '3ecnn13.tflite' \"$KERAS_MODELS_ABSOLUTE_PATH\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "3ecnn13.tpu.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}